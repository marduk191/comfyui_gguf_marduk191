{
  "last_node_id": 9,
  "last_link_id": 11,
  "nodes": [
    {
      "id": 1,
      "type": "GGUFCheckpointLoader",
      "pos": [50, 50],
      "size": {"0": 350, "1": 150},
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {"name": "MODEL", "type": "MODEL", "links": [1]},
        {"name": "CLIP", "type": "CLIP", "links": [2]},
        {"name": "VAE", "type": "VAE", "links": [3]}
      ],
      "properties": {},
      "widgets_values": [
        "base_model_q4k.gguf",
        "true",
        "true",
        ""
      ],
      "title": "Load Base GGUF Model"
    },
    {
      "id": 2,
      "type": "GGUFLoraLoader",
      "pos": [450, 50],
      "size": {"0": 350, "1": 180},
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [
        {"name": "model", "type": "MODEL", "link": 1},
        {"name": "clip", "type": "CLIP", "link": 2}
      ],
      "outputs": [
        {"name": "MODEL", "type": "MODEL", "links": [4]},
        {"name": "CLIP", "type": "CLIP", "links": [5, 6]}
      ],
      "properties": {},
      "widgets_values": [
        "style_lora_q8.gguf",
        1.0,
        1.0,
        ""
      ],
      "title": "Apply GGUF LoRA"
    },
    {
      "id": 3,
      "type": "CLIPTextEncode",
      "pos": [850, 50],
      "size": {"0": 400, "1": 200},
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [
        {"name": "clip", "type": "CLIP", "link": 5}
      ],
      "outputs": [
        {"name": "CONDITIONING", "type": "CONDITIONING", "links": [7]}
      ],
      "properties": {},
      "widgets_values": [
        "anime style, 1girl, detailed face, colorful"
      ],
      "title": "Positive (with LoRA trigger)"
    },
    {
      "id": 4,
      "type": "CLIPTextEncode",
      "pos": [850, 300],
      "size": {"0": 400, "1": 200},
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {"name": "clip", "type": "CLIP", "link": 6}
      ],
      "outputs": [
        {"name": "CONDITIONING", "type": "CONDITIONING", "links": [8]}
      ],
      "properties": {},
      "widgets_values": [
        "low quality, blurry"
      ],
      "title": "Negative"
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": [850, 550],
      "size": {"0": 315, "1": 106},
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {"name": "LATENT", "type": "LATENT", "links": [9]}
      ],
      "properties": {},
      "widgets_values": [
        768,
        768,
        1
      ]
    },
    {
      "id": 6,
      "type": "KSampler",
      "pos": [1300, 50],
      "size": {"0": 315, "1": 474},
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {"name": "model", "type": "MODEL", "link": 4},
        {"name": "positive", "type": "CONDITIONING", "link": 7},
        {"name": "negative", "type": "CONDITIONING", "link": 8},
        {"name": "latent_image", "type": "LATENT", "link": 9}
      ],
      "outputs": [
        {"name": "LATENT", "type": "LATENT", "links": [10]}
      ],
      "properties": {},
      "widgets_values": [
        9999,
        "fixed",
        30,
        7.0,
        "dpmpp_2m",
        "karras",
        1.0
      ]
    },
    {
      "id": 7,
      "type": "VAEDecode",
      "pos": [1650, 50],
      "size": {"0": 210, "1": 46},
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {"name": "samples", "type": "LATENT", "link": 10},
        {"name": "vae", "type": "VAE", "link": 3}
      ],
      "outputs": [
        {"name": "IMAGE", "type": "IMAGE", "links": [11]}
      ],
      "properties": {}
    },
    {
      "id": 8,
      "type": "SaveImage",
      "pos": [1900, 50],
      "size": {"0": 315, "1": 270},
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {"name": "images", "type": "IMAGE", "link": 11}
      ],
      "properties": {},
      "widgets_values": [
        "gguf_lora_output"
      ]
    },
    {
      "id": 9,
      "type": "Note",
      "pos": [50, 250],
      "size": {"0": 350, "1": 400},
      "flags": {},
      "order": 8,
      "mode": 0,
      "properties": {},
      "widgets_values": [
        "GGUF LoRA Workflow\n\nApply quantized LoRA to quantized base model!\n\nðŸŽ¨ GGUF LoRA Loader Features:\nâ€¢ strength_model: 0.0 to 20.0\n  - 1.0 = normal strength\n  - < 1.0 = subtle effect\n  - > 1.0 = amplified effect\n  - Negative values invert effect\n\nâ€¢ strength_clip: 0.0 to 20.0\n  - Independent CLIP control\n  - Affects prompt understanding\n\nðŸ’¡ Tips:\n1. Start with 1.0/1.0 for both\n2. Adjust model strength for style\n3. Keep CLIP strength ~1.0\n4. Use negative for anti-LoRA\n\nðŸ“¦ LoRA Quantization:\nâ€¢ Q8_0: Best quality (recommended)\nâ€¢ Q4_K: Good compression\nâ€¢ F16: No quantization\n\nâœ¨ Benefits:\nâ€¢ Smaller LoRA files\nâ€¢ Fast loading\nâ€¢ Compatible with GGUF base models\nâ€¢ Stack multiple quantized LoRAs"
      ],
      "title": "Info: GGUF LoRA"
    }
  ],
  "links": [
    [1, 1, 0, 2, 0, "MODEL"],
    [2, 1, 1, 2, 1, "CLIP"],
    [3, 1, 2, 7, 1, "VAE"],
    [4, 2, 0, 6, 0, "MODEL"],
    [5, 2, 1, 3, 0, "CLIP"],
    [6, 2, 1, 4, 0, "CLIP"],
    [7, 3, 0, 6, 1, "CONDITIONING"],
    [8, 4, 0, 6, 2, "CONDITIONING"],
    [9, 5, 0, 6, 3, "LATENT"],
    [10, 6, 0, 7, 0, "LATENT"],
    [11, 7, 0, 8, 0, "IMAGE"]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}
